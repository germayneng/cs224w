{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XuXWJLEm2UWS"
   },
   "source": [
    "# **CS224W - Colab 2** Done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8gzsP50bF6Gb"
   },
   "source": [
    "In this Colab, we will construct our own graph neural network by using PyTorch Geometric (PyG) and apply the model on two of Open Graph Benchmark (OGB) datasets. Those two datasets are used to benchmark the model performance on two different graph-related tasks. One is node property prediction, predicting properties of single nodes. Another one is graph property prediction, predicting the entire graphs or subgraphs.\n",
    "\n",
    "At first, we will learn how PyTorch Geometric stores the graphs in PyTorch tensor.\n",
    "\n",
    "We will then load and take a quick look on one of the Open Graph Benchmark (OGB) datasets by using the `ogb` package. OGB is a collection of realistic, large-scale, and diverse benchmark datasets for machine learning on graphs. The `ogb` package not only provides the data loader of the dataset but also the evaluator.\n",
    "\n",
    "At last, we will build our own graph neural networks by using PyTorch Geometric. And then apply and evaluate the models on node property prediction and grpah property prediction tasks.\n",
    "\n",
    "**Note**: Make sure to **sequentially run all the cells in each section**, so that the intermediate variables / packages will carry over to the next cell\n",
    "\n",
    "Have fun on Colab 2 :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZGKqVEbbMEzf"
   },
   "source": [
    "# Device\n",
    "You might need to use GPU for this Colab.\n",
    "\n",
    "Please click `Runtime` and then `Change runtime type`. Then set the `hardware accelerator` to **GPU**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B0NiFL6OLpaJ"
   },
   "source": [
    "# Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2020 NVIDIA Corporation\n",
      "Built on Wed_Jul_22_19:09:09_PDT_2020\n",
      "Cuda compilation tools, release 11.0, V11.0.221\n",
      "Build cuda_11.0_bu.TC445_37.28845127_0\n"
     ]
    }
   ],
   "source": [
    "!nvcc --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                        Version             Location\n",
      "------------------------------ ------------------- --------------\n",
      "absl-py                        0.12.0\n",
      "adal                           1.2.6\n",
      "affine                         2.3.0\n",
      "aiobotocore                    1.3.0\n",
      "aiohttp                        3.7.4\n",
      "aiohttp-cors                   0.7.0\n",
      "aioitertools                   0.7.1\n",
      "aioredis                       1.3.1\n",
      "albumentations                 0.5.2\n",
      "alembic                        1.5.8\n",
      "allennlp                       2.3.0\n",
      "altair                         4.1.0\n",
      "annoy                          1.17.0\n",
      "ansiwrap                       0.8.4\n",
      "appdirs                        1.4.4\n",
      "argon2-cffi                    20.1.0\n",
      "arrow                          1.0.3\n",
      "arviz                          0.11.2\n",
      "asn1crypto                     1.4.0\n",
      "astunparse                     1.6.3\n",
      "async-generator                1.10\n",
      "async-timeout                  3.0.1\n",
      "attrs                          20.3.0\n",
      "audioread                      2.1.9\n",
      "autocfg                        0.0.8\n",
      "autogluon.core                 0.1.0\n",
      "autograd                       1.3\n",
      "Babel                          2.9.0\n",
      "backcall                       0.2.0\n",
      "backports.functools-lru-cache  1.6.3\n",
      "basemap                        1.2.1\n",
      "bayesian-optimization          1.2.0\n",
      "bayespy                        0.5.22\n",
      "bcrypt                         3.2.0\n",
      "binaryornot                    0.4.4\n",
      "biopython                      1.78\n",
      "black                          20.8b1\n",
      "bleach                         3.3.0\n",
      "blessings                      1.7\n",
      "blinker                        1.4\n",
      "blis                           0.7.4\n",
      "bokeh                          2.3.1\n",
      "Boruta                         0.3\n",
      "boto3                          1.17.53\n",
      "botocore                       1.20.53\n",
      "bq-helper                      0.4.1               /src/bq-helper\n",
      "bqplot                         0.12.25\n",
      "branca                         0.4.2\n",
      "brewer2mpl                     1.4.1\n",
      "brotlipy                       0.7.0\n",
      "cachetools                     4.2.1\n",
      "caip-notebooks-serverextension 1.0.0\n",
      "Cartopy                        0.18.0\n",
      "catalogue                      1.0.0\n",
      "catalyst                       21.4.1\n",
      "catboost                       0.25.1\n",
      "category-encoders              2.2.2\n",
      "certifi                        2020.12.5\n",
      "cesium                         0.9.12\n",
      "cffi                           1.14.5\n",
      "cftime                         1.4.1\n",
      "chardet                        4.0.0\n",
      "cleverhans                     3.0.1\n",
      "click                          7.1.2\n",
      "click-plugins                  1.1.1\n",
      "cliff                          3.7.0\n",
      "cligj                          0.7.1\n",
      "cloud-tpu-client               0.10\n",
      "cloudpickle                    1.6.0\n",
      "cmaes                          0.8.2\n",
      "cmd2                           1.5.0\n",
      "cmdstanpy                      0.9.5\n",
      "cmudict                        0.4.5\n",
      "colorama                       0.4.4\n",
      "colorcet                       2.0.6\n",
      "colorful                       0.5.4\n",
      "colorlog                       5.0.1\n",
      "colorlover                     0.3.0\n",
      "conda                          4.10.1\n",
      "conda-package-handling         1.7.2\n",
      "configparser                   5.0.2\n",
      "ConfigSpace                    0.4.18\n",
      "confuse                        1.4.0\n",
      "contextily                     1.1.0\n",
      "contextlib2                    0.6.0.post1\n",
      "convertdate                    2.3.2\n",
      "cookiecutter                   1.7.2\n",
      "cryptography                   3.4.7\n",
      "cudf                           0.16.0\n",
      "cufflinks                      0.17.3\n",
      "cuml                           0.16.0\n",
      "cupy                           8.0.0\n",
      "cupy-cuda110                   8.6.0\n",
      "CVXcanon                       0.1.2\n",
      "cvxpy                          1.1.7\n",
      "cycler                         0.10.0\n",
      "cymem                          2.0.5\n",
      "cysignals                      1.10.3\n",
      "Cython                         0.29.23\n",
      "cytoolz                        0.11.0\n",
      "dask                           2021.4.0\n",
      "dask-cudf                      0.16.0\n",
      "dataclasses                    0.6\n",
      "datashader                     0.12.1\n",
      "datashape                      0.5.2\n",
      "datatable                      0.11.1\n",
      "deap                           1.3.1\n",
      "decorator                      4.4.2\n",
      "decord                         0.5.2\n",
      "deepdish                       0.3.6\n",
      "defusedxml                     0.7.1\n",
      "Delorean                       1.0.0\n",
      "Deprecated                     1.2.12\n",
      "descartes                      1.1.0\n",
      "dill                           0.3.3\n",
      "dipy                           1.4.0\n",
      "distributed                    2021.4.0\n",
      "dlib                           19.22.0\n",
      "dm-tree                        0.1.6\n",
      "docker                         4.4.4\n",
      "docker-pycreds                 0.4.0\n",
      "docutils                       0.17.1\n",
      "earthengine-api                0.1.261\n",
      "easydev                        0.11.0\n",
      "easyocr                        1.3.0.1\n",
      "ecos                           2.0.7.post1\n",
      "eli5                           0.11.0\n",
      "emoji                          1.2.0\n",
      "en-core-web-lg                 2.3.1\n",
      "en-core-web-sm                 2.3.1\n",
      "entrypoints                    0.3\n",
      "ephem                          3.7.7.1\n",
      "essentia                       2.1b6.dev374\n",
      "fancyimpute                    0.5.5\n",
      "fastai                         2.3.0\n",
      "fastavro                       1.4.0\n",
      "fastcore                       1.3.19\n",
      "fastprogress                   1.0.0\n",
      "fastrlock                      0.6\n",
      "fasttext                       0.9.2\n",
      "fbpca                          1.0\n",
      "fbprophet                      0.7.1\n",
      "feather-format                 0.4.1\n",
      "featuretools                   0.23.3\n",
      "filelock                       3.0.12\n",
      "Fiona                          1.8.18\n",
      "fitter                         1.3.0\n",
      "flake8                         3.9.1\n",
      "flashtext                      2.7\n",
      "Flask                          1.1.2\n",
      "flatbuffers                    1.12\n",
      "folium                         0.12.1\n",
      "fsspec                         0.8.7\n",
      "funcy                          1.15\n",
      "fury                           0.7.0\n",
      "future                         0.18.2\n",
      "fuzzywuzzy                     0.18.0\n",
      "gast                           0.3.3\n",
      "gatspy                         0.3\n",
      "gcsfs                          0.7.2\n",
      "GDAL                           3.2.1\n",
      "gensim                         4.0.1\n",
      "geographiclib                  1.50\n",
      "Geohash                        1.0\n",
      "geojson                        2.5.0\n",
      "geopandas                      0.9.0\n",
      "geoplot                        0.4.1\n",
      "geopy                          2.1.0\n",
      "geoviews                       1.9.1\n",
      "ggplot                         0.11.5\n",
      "gitdb                          4.0.7\n",
      "GitPython                      3.1.14\n",
      "gluoncv                        0.10.1.post0\n",
      "gluonnlp                       0.10.0\n",
      "google-api-core                1.26.2\n",
      "google-api-python-client       1.8.0\n",
      "google-auth                    1.26.1\n",
      "google-auth-httplib2           0.0.4\n",
      "google-auth-oauthlib           0.4.3\n",
      "google-cloud-aiplatform        0.6.0a1\n",
      "google-cloud-automl            1.0.1\n",
      "google-cloud-bigquery          2.2.0\n",
      "google-cloud-bigtable          1.4.0\n",
      "google-cloud-core              1.6.0\n",
      "google-cloud-dataproc          1.1.1\n",
      "google-cloud-datastore         1.12.0\n",
      "google-cloud-firestore         1.8.1\n",
      "google-cloud-kms               1.4.0\n",
      "google-cloud-language          2.0.0\n",
      "google-cloud-logging           1.15.1\n",
      "google-cloud-monitoring        1.1.0\n",
      "google-cloud-pubsub            1.7.0\n",
      "google-cloud-scheduler         1.3.0\n",
      "google-cloud-spanner           1.17.1\n",
      "google-cloud-speech            1.3.2\n",
      "google-cloud-storage           1.30.0\n",
      "google-cloud-tasks             1.5.0\n",
      "google-cloud-translate         3.1.0\n",
      "google-cloud-videointelligence 2.1.0\n",
      "google-cloud-vision            2.3.1\n",
      "google-crc32c                  1.1.2\n",
      "google-pasta                   0.2.0\n",
      "google-resumable-media         1.2.0\n",
      "googleapis-common-protos       1.53.0\n",
      "gplearn                        0.4.1\n",
      "gpustat                        0.6.0\n",
      "gpxpy                          1.4.2\n",
      "graphviz                       0.8.4\n",
      "greenlet                       1.0.0\n",
      "grpc-google-iam-v1             0.12.3\n",
      "grpcio                         1.32.0\n",
      "grpcio-gcp                     0.2.2\n",
      "gym                            0.18.0\n",
      "h2o                            3.32.1.1\n",
      "h5py                           2.10.0\n",
      "haversine                      2.3.0\n",
      "HeapDict                       1.0.1\n",
      "hep-ml                         0.6.2\n",
      "hijri-converter                2.1.1\n",
      "hiredis                        2.0.0\n",
      "hmmlearn                       0.2.5\n",
      "holidays                       0.11.1\n",
      "holoviews                      1.14.3\n",
      "hpsklearn                      0.1.0\n",
      "html5lib                       1.1\n",
      "htmlmin                        0.1.12\n",
      "httplib2                       0.19.0\n",
      "httplib2shim                   0.0.3\n",
      "humanize                       3.4.1\n",
      "hunspell                       0.5.5\n",
      "husl                           4.0.3\n",
      "hyperopt                       0.2.5\n",
      "hypertools                     0.6.3\n",
      "hypothesis                     6.10.0\n",
      "ibis-framework                 1.4.0\n",
      "idna                           2.10\n",
      "imagecodecs                    2021.3.31\n",
      "ImageHash                      4.2.0\n",
      "imageio                        2.9.0\n",
      "imbalanced-learn               0.8.0\n",
      "imgaug                         0.4.0\n",
      "implicit                       0.4.4\n",
      "importlib-metadata             3.4.0\n",
      "iniconfig                      1.1.1\n",
      "ipykernel                      5.5.0\n",
      "ipympl                         0.7.0\n",
      "ipython                        7.22.0\n",
      "ipython-genutils               0.2.0\n",
      "ipython-sql                    0.3.9\n",
      "ipywidgets                     7.6.3\n",
      "iso3166                        1.0.1\n",
      "isoweek                        1.3.3\n",
      "itsdangerous                   1.1.0\n",
      "Janome                         0.4.1\n",
      "jax                            0.2.12\n",
      "jaxlib                         0.1.64+cuda110\n",
      "jedi                           0.18.0\n",
      "jieba                          0.42.1\n",
      "Jinja2                         2.11.3\n",
      "jinja2-time                    0.2.0\n",
      "jmespath                       0.10.0\n",
      "joblib                         1.0.1\n",
      "json5                          0.9.5\n",
      "jsonnet                        0.17.0\n",
      "jsonschema                     3.2.0\n",
      "jupyter-client                 6.1.12\n",
      "jupyter-console                6.4.0\n",
      "jupyter-core                   4.7.1\n",
      "jupyter-http-over-ws           0.0.8\n",
      "jupyterlab                     1.2.16\n",
      "jupyterlab-git                 0.11.0\n",
      "jupyterlab-pygments            0.1.2\n",
      "jupyterlab-server              1.2.0\n",
      "jupyterlab-widgets             1.0.0\n",
      "kaggle                         1.5.12\n",
      "kaggle-environments            1.7.11\n",
      "Keras                          2.4.3\n",
      "Keras-Preprocessing            1.1.2\n",
      "keras-tuner                    1.0.2\n",
      "kiwisolver                     1.3.1\n",
      "kmapper                        2.0.0\n",
      "kmodes                         0.11.0\n",
      "knnimpute                      0.1.0\n",
      "korean-lunar-calendar          0.2.1\n",
      "kornia                         0.5.0\n",
      "kubernetes                     12.0.1\n",
      "langid                         1.1.6\n",
      "learntools                     0.3.4\n",
      "leven                          1.0.4\n",
      "libcst                         0.3.18\n",
      "librosa                        0.8.0\n",
      "lightfm                        1.16\n",
      "lightgbm                       3.2.0\n",
      "lime                           0.2.0.1\n",
      "line-profiler                  3.1.0\n",
      "llvmlite                       0.36.0\n",
      "lmdb                           1.2.0\n",
      "lml                            0.1.0\n",
      "locket                         0.2.1\n",
      "LunarCalendar                  0.0.9\n",
      "lxml                           4.6.3\n",
      "Mako                           1.1.4\n",
      "mapclassify                    2.4.2\n",
      "marisa-trie                    0.7.5\n",
      "Markdown                       3.3.4\n",
      "markovify                      0.9.0\n",
      "MarkupSafe                     1.1.1\n",
      "matplotlib                     3.4.1\n",
      "matplotlib-venn                0.11.6\n",
      "matrixprofile                  1.1.10\n",
      "mccabe                         0.6.1\n",
      "memory-profiler                0.58.0\n",
      "mercantile                     1.1.6\n",
      "missingno                      0.4.2\n",
      "mistune                        0.8.4\n",
      "mizani                         0.7.3\n",
      "ml-metrics                     0.1.4\n",
      "mlcrate                        0.2.0\n",
      "mlens                          0.2.3\n",
      "mlxtend                        0.18.0\n",
      "mmh3                           3.0.0\n",
      "mne                            0.22.1\n",
      "mnist                          0.2.2\n",
      "mock                           4.0.3\n",
      "more-itertools                 8.7.0\n",
      "mpld3                          0.5.2\n",
      "mpmath                         1.2.1\n",
      "msgpack                        1.0.2\n",
      "msgpack-numpy                  0.4.7.1\n",
      "multidict                      5.1.0\n",
      "multipledispatch               0.6.0\n",
      "multiprocess                   0.70.11.1\n",
      "munch                          2.5.0\n",
      "murmurhash                     1.0.5\n",
      "mxnet-cu110                    1.8.0.post0\n",
      "mypy-extensions                0.4.3\n",
      "nb-conda                       2.2.1\n",
      "nb-conda-kernels               2.3.1\n",
      "nbclient                       0.5.3\n",
      "nbconvert                      6.0.7\n",
      "nbdime                         2.1.0\n",
      "nbformat                       5.1.2\n",
      "nest-asyncio                   1.4.3\n",
      "netCDF4                        1.5.6\n",
      "networkx                       2.5\n",
      "nibabel                        3.2.1\n",
      "nilearn                        0.7.1\n",
      "nltk                           3.2.4\n",
      "nnabla                         1.19.0\n",
      "nnabla-ext-cuda110             1.19.0\n",
      "nose                           1.3.7\n",
      "notebook                       6.3.0\n",
      "notebook-executor              0.2\n",
      "numba                          0.53.1\n",
      "numexpr                        2.7.3\n",
      "numpy                          1.19.5\n",
      "nvidia-ml-py3                  7.352.0\n",
      "oauth2client                   4.1.3\n",
      "oauthlib                       3.0.1\n",
      "odfpy                          1.4.1\n",
      "olefile                        0.46\n",
      "onnx                           1.8.1\n",
      "opencensus                     0.7.12\n",
      "opencensus-context             0.1.2\n",
      "opencv-python                  4.5.1.48\n",
      "opencv-python-headless         4.5.1.48\n",
      "openslide-python               1.1.2\n",
      "opt-einsum                     3.3.0\n",
      "optuna                         2.7.0\n",
      "orderedmultidict               1.0.1\n",
      "ortools                        8.2.8710\n",
      "osmnx                          1.0.1\n",
      "osqp                           0.6.2.post0\n",
      "overrides                      3.1.0\n",
      "packaging                      20.9\n",
      "palettable                     3.3.0\n",
      "pandas                         1.1.5\n",
      "pandas-datareader              0.9.0\n",
      "pandas-profiling               2.11.0\n",
      "pandas-summary                 0.0.7\n",
      "pandasql                       0.7.3\n",
      "pandocfilters                  1.4.2\n",
      "panel                          0.11.3\n",
      "papermill                      2.3.3\n",
      "param                          1.10.1\n",
      "paramiko                       2.7.2\n",
      "parso                          0.8.1\n",
      "partd                          1.2.0\n",
      "path                           15.1.2\n",
      "path.py                        12.5.0\n",
      "pathos                         0.2.7\n",
      "pathspec                       0.8.1\n",
      "pathtools                      0.1.2\n",
      "patsy                          0.5.1\n",
      "pbr                            5.5.1\n",
      "pdf2image                      1.14.0\n",
      "PDPbox                         0.2.1\n",
      "pexpect                        4.8.0\n",
      "phik                           0.11.2\n",
      "pickleshare                    0.7.5\n",
      "Pillow                         7.2.0\n",
      "pip                            21.0.1\n",
      "plac                           1.1.3\n",
      "plotly                         4.14.3\n",
      "plotly-express                 0.4.1\n",
      "plotnine                       0.8.0\n",
      "pluggy                         0.13.1\n",
      "polyglot                       16.7.4\n",
      "pooch                          1.3.0\n",
      "portalocker                    2.3.0\n",
      "pox                            0.2.9\n",
      "poyo                           0.5.0\n",
      "ppca                           0.0.4\n",
      "ppft                           1.6.6.3\n",
      "preprocessing                  0.1.13\n",
      "preshed                        3.0.5\n",
      "prettytable                    2.1.0\n",
      "prometheus-client              0.9.0\n",
      "promise                        2.3\n",
      "prompt-toolkit                 3.0.18\n",
      "pronouncing                    0.2.0\n",
      "proto-plus                     1.18.1\n",
      "protobuf                       3.15.8\n",
      "psutil                         5.8.0\n",
      "ptyprocess                     0.7.0\n",
      "pudb                           2020.1\n",
      "py                             1.10.0\n",
      "py-lz4framed                   0.14.0\n",
      "py-spy                         0.3.5\n",
      "py-stringmatching              0.4.2\n",
      "py-stringsimjoin               0.3.2\n",
      "pyaml                          20.4.0\n",
      "PyArabic                       0.6.10\n",
      "pyarrow                        1.0.1\n",
      "pyasn1                         0.4.8\n",
      "pyasn1-modules                 0.2.7\n",
      "PyAstronomy                    0.16.0\n",
      "pybind11                       2.6.2\n",
      "pycodestyle                    2.7.0\n",
      "pycosat                        0.6.3\n",
      "pycountry                      20.7.3\n",
      "pycparser                      2.20\n",
      "pycrypto                       2.6.1\n",
      "pyct                           0.4.8\n",
      "pycuda                         2021.1\n",
      "pydash                         5.0.0\n",
      "pydegensac                     0.1.2\n",
      "pydicom                        2.1.2\n",
      "pydot                          1.4.2\n",
      "pydub                          0.25.1\n",
      "pyemd                          0.5.1\n",
      "pyexcel-io                     0.6.4\n",
      "pyexcel-ods                    0.6.0\n",
      "pyfasttext                     0.4.6\n",
      "pyflakes                       2.3.1\n",
      "pyglet                         1.5.0\n",
      "Pygments                       2.8.1\n",
      "PyJWT                          2.0.1\n",
      "pykalman                       0.9.5\n",
      "pyLDAvis                       3.3.1\n",
      "pymc3                          3.11.2\n",
      "PyMeeus                        0.5.11\n",
      "pymongo                        3.11.3\n",
      "Pympler                        0.9\n",
      "PyNaCl                         1.4.0\n",
      "pynndescent                    0.5.2\n",
      "pynvml                         8.0.4\n",
      "pynvrtc                        9.2\n",
      "pyocr                          0.8\n",
      "pyOpenSSL                      20.0.1\n",
      "pyparsing                      2.4.7\n",
      "pyPdf                          1.13\n",
      "pyperclip                      1.8.2\n",
      "PyPrind                        2.11.3\n",
      "pyproj                         2.6.1.post1\n",
      "PyQt5                          5.12.3\n",
      "PyQt5-sip                      4.19.18\n",
      "PyQtChart                      5.12\n",
      "PyQtWebEngine                  5.12.1\n",
      "pyrsistent                     0.17.3\n",
      "pysal                          2.1.0\n",
      "pyshp                          2.1.3\n",
      "PySocks                        1.7.1\n",
      "pystan                         2.19.1.1\n",
      "pytesseract                    0.3.7\n",
      "pytest                         6.2.3\n",
      "pytext-nlp                     0.1.2\n",
      "python-bidi                    0.4.2\n",
      "python-dateutil                2.8.1\n",
      "python-editor                  1.0.4\n",
      "python-igraph                  0.9.1\n",
      "python-Levenshtein             0.12.2\n",
      "python-louvain                 0.15\n",
      "python-slugify                 4.0.1\n",
      "pytools                        2021.2.3\n",
      "pytorch-ignite                 0.4.4\n",
      "pytorch-lightning              1.2.8\n",
      "pytz                           2021.1\n",
      "PyUpSet                        0.1.1.post7\n",
      "pyviz-comms                    2.0.1\n",
      "PyWavelets                     1.1.1\n",
      "PyYAML                         5.3.1\n",
      "pyzmq                          22.0.3\n",
      "qdldl                          0.1.5.post0\n",
      "qgrid                          1.3.1\n",
      "qtconsole                      5.0.3\n",
      "QtPy                           1.9.0\n",
      "randomgen                      1.16.6\n",
      "rasterio                       1.2.2\n",
      "ray                            1.2.0\n",
      "redis                          3.5.3\n",
      "regex                          2021.3.17\n",
      "requests                       2.25.1\n",
      "requests-oauthlib              1.3.0\n",
      "resampy                        0.2.2\n",
      "retrying                       1.3.3\n",
      "rgf-python                     3.9.0\n",
      "rmm                            0.16.0\n",
      "rsa                            4.7.2\n",
      "Rtree                          0.9.7\n",
      "ruamel-yaml-conda              0.15.80\n",
      "s2sphere                       0.2.5\n",
      "s3fs                           0.6.0\n",
      "s3transfer                     0.3.7\n",
      "sacremoses                     0.0.45\n",
      "scattertext                    0.1.2\n",
      "scikit-image                   0.18.1\n",
      "scikit-learn                   0.24.1\n",
      "scikit-multilearn              0.2.0\n",
      "scikit-optimize                0.8.1\n",
      "scikit-plot                    0.3.7\n",
      "scikit-surprise                1.1.1\n",
      "scipy                          1.5.4\n",
      "scs                            2.1.3\n",
      "seaborn                        0.11.1\n",
      "semver                         2.13.0\n",
      "Send2Trash                     1.5.0\n",
      "sentencepiece                  0.1.95\n",
      "sentry-sdk                     1.0.0\n",
      "setuptools                     49.6.0.post20210108\n",
      "setuptools-git                 1.2\n",
      "shap                           0.39.0\n",
      "Shapely                        1.7.1\n",
      "shortuuid                      1.0.1\n",
      "SimpleITK                      2.0.2\n",
      "simplejson                     3.17.2\n",
      "six                            1.15.0\n",
      "sklearn                        0.0\n",
      "sklearn-contrib-py-earth       0.1.0+1.gdde5f89\n",
      "sklearn-pandas                 2.1.0\n",
      "slicer                         0.0.7\n",
      "smart-open                     5.0.0\n",
      "smhasher                       0.150.1\n",
      "smmap                          3.0.5\n",
      "snuggs                         1.4.7\n",
      "sortedcontainers               2.3.0\n",
      "SoundFile                      0.10.3.post1\n",
      "spacy                          2.3.5\n",
      "spectral                       0.22.2\n",
      "sphinx-rtd-theme               0.2.4\n",
      "SQLAlchemy                     1.4.3\n",
      "sqlparse                       0.4.1\n",
      "squarify                       0.4.3\n",
      "srsly                          1.0.5\n",
      "statsmodels                    0.12.2\n",
      "stemming                       1.0.1\n",
      "stevedore                      3.3.0\n",
      "stop-words                     2018.7.23\n",
      "stopit                         1.1.2\n",
      "stumpy                         1.8.0\n",
      "subprocess32                   3.5.4\n",
      "sympy                          1.8\n",
      "tables                         3.6.1\n",
      "tabulate                       0.8.9\n",
      "tangled-up-in-unicode          0.0.7\n",
      "tblib                          1.7.0\n",
      "tenacity                       7.0.0\n",
      "tensorboard                    2.4.1\n",
      "tensorboard-plugin-wit         1.8.0\n",
      "tensorboardX                   2.2\n",
      "tensorflow                     2.4.1\n",
      "tensorflow-addons              0.12.1\n",
      "tensorflow-cloud               0.1.13\n",
      "tensorflow-datasets            3.0.0\n",
      "tensorflow-estimator           2.4.0\n",
      "tensorflow-gcs-config          2.1.7\n",
      "tensorflow-hub                 0.12.0\n",
      "tensorflow-metadata            0.29.0\n",
      "tensorflow-probability         0.12.2\n",
      "tensorpack                     0.11\n",
      "termcolor                      1.1.0\n",
      "terminado                      0.9.3\n",
      "terminaltables                 3.1.0\n",
      "testpath                       0.4.4\n",
      "text-unidecode                 1.3\n",
      "textblob                       0.15.3\n",
      "texttable                      1.6.3\n",
      "textwrap3                      0.9.2\n",
      "Theano                         1.0.5\n",
      "Theano-PyMC                    1.1.2\n",
      "thinc                          7.4.5\n",
      "threadpoolctl                  2.1.0\n",
      "tifffile                       2021.4.8\n",
      "tokenizers                     0.10.2\n",
      "toml                           0.10.2\n",
      "toolz                          0.11.1\n",
      "torch                          1.7.0\n",
      "torchaudio                     0.7.0a0+ac17b64\n",
      "torchmetrics                   0.2.0\n",
      "torchtext                      0.8.0a0+cd6902d\n",
      "torchvision                    0.8.1\n",
      "tornado                        6.1\n",
      "TPOT                           0.11.7\n",
      "tqdm                           4.59.0\n",
      "traitlets                      5.0.5\n",
      "traittypes                     0.2.1\n",
      "transformers                   4.5.1\n",
      "treelite                       0.93\n",
      "treelite-runtime               0.93\n",
      "trueskill                      0.4.5\n",
      "tsfresh                        0.18.0\n",
      "typed-ast                      1.4.2\n",
      "typeguard                      2.12.0\n",
      "typing-extensions              3.7.4.3\n",
      "typing-inspect                 0.6.0\n",
      "tzlocal                        2.1\n",
      "ucx-py                         0.16.0\n",
      "umap-learn                     0.5.1\n",
      "Unidecode                      1.2.0\n",
      "update-checker                 0.18.0\n",
      "uritemplate                    3.0.1\n",
      "urllib3                        1.26.4\n",
      "urwid                          2.1.2\n",
      "vecstack                       0.4.0\n",
      "visions                        0.6.0\n",
      "vowpalwabbit                   8.10.1\n",
      "vtk                            9.0.1\n",
      "Wand                           0.6.6\n",
      "wandb                          0.10.26\n",
      "wasabi                         0.8.2\n",
      "wavio                          0.0.4\n",
      "wcwidth                        0.2.5\n",
      "webencodings                   0.5.1\n",
      "websocket-client               0.57.0\n",
      "Werkzeug                       1.0.1\n",
      "wfdb                           3.3.0\n",
      "wheel                          0.36.2\n",
      "whichcraft                     0.6.1\n",
      "widgetsnbextension             3.5.1\n",
      "Wordbatch                      1.4.6\n",
      "wordcloud                      1.8.1\n",
      "wordsegment                    1.3.1\n",
      "wrapt                          1.12.1\n",
      "xarray                         0.17.0\n",
      "xgboost                        1.4.0\n",
      "xvfbwrapper                    0.2.9\n",
      "yacs                           0.1.8\n",
      "yarl                           1.6.3\n",
      "yellowbrick                    1.3.post1\n",
      "zict                           2.0.0\n",
      "zipp                           3.4.1\n"
     ]
    }
   ],
   "source": [
    "!pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ogb\n",
      "  Downloading ogb-1.3.1-py3-none-any.whl (67 kB)\n",
      "\u001b[K     |████████████████████████████████| 67 kB 652 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pandas>=0.24.0 in /opt/conda/lib/python3.7/site-packages (from ogb) (1.1.5)\n",
      "Requirement already satisfied: tqdm>=4.29.0 in /opt/conda/lib/python3.7/site-packages (from ogb) (4.59.0)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in /opt/conda/lib/python3.7/site-packages (from ogb) (0.24.1)\n",
      "Requirement already satisfied: torch>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from ogb) (1.7.0)\n",
      "Collecting outdated>=0.2.0\n",
      "  Downloading outdated-0.2.1-py3-none-any.whl (7.5 kB)\n",
      "Requirement already satisfied: urllib3>=1.24.0 in /opt/conda/lib/python3.7/site-packages (from ogb) (1.26.4)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.7/site-packages (from ogb) (1.15.0)\n",
      "Requirement already satisfied: numpy>=1.16.0 in /opt/conda/lib/python3.7/site-packages (from ogb) (1.19.5)\n",
      "Collecting littleutils\n",
      "  Downloading littleutils-0.2.2.tar.gz (6.6 kB)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from outdated>=0.2.0->ogb) (2.25.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas>=0.24.0->ogb) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /opt/conda/lib/python3.7/site-packages (from pandas>=0.24.0->ogb) (2021.1)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from scikit-learn>=0.20.0->ogb) (1.0.1)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /opt/conda/lib/python3.7/site-packages (from scikit-learn>=0.20.0->ogb) (1.5.4)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn>=0.20.0->ogb) (2.1.0)\n",
      "Requirement already satisfied: future in /opt/conda/lib/python3.7/site-packages (from torch>=1.6.0->ogb) (0.18.2)\n",
      "Requirement already satisfied: typing_extensions in /opt/conda/lib/python3.7/site-packages (from torch>=1.6.0->ogb) (3.7.4.3)\n",
      "Requirement already satisfied: dataclasses in /opt/conda/lib/python3.7/site-packages (from torch>=1.6.0->ogb) (0.6)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->outdated>=0.2.0->ogb) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests->outdated>=0.2.0->ogb) (4.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->outdated>=0.2.0->ogb) (2020.12.5)\n",
      "Building wheels for collected packages: littleutils\n",
      "  Building wheel for littleutils (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for littleutils: filename=littleutils-0.2.2-py3-none-any.whl size=7048 sha256=7b15234a3b74150d5650b420fee088230a983ff3db87ec9e5f57e49e5f975167\n",
      "  Stored in directory: /root/.cache/pip/wheels/d6/64/cd/32819b511a488e4993f2fab909a95330289c3f4e0f6ef4676d\n",
      "Successfully built littleutils\n",
      "Installing collected packages: littleutils, outdated, ogb\n",
      "Successfully installed littleutils-0.2.2 ogb-1.3.1 outdated-0.2.1\n"
     ]
    }
   ],
   "source": [
    "!pip install -q torch-scatter -f https://pytorch-geometric.com/whl/torch-1.7.0+cu110.html\n",
    "!pip install -q torch-sparse -f https://pytorch-geometric.com/whl/torch-1.7.0+cu110.html\n",
    "!pip install -q torch-geometric\n",
    "!pip install ogb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "By2oyBw7Lrh5"
   },
   "outputs": [],
   "source": [
    "# !pip install -q torch-scatter -f https://pytorch-geometric.com/whl/torch-1.7.0+cu102.html\n",
    "# !pip install -q torch-sparse -f https://pytorch-geometric.com/whl/torch-1.7.0+cu102.html\n",
    "# !pip install -q torch-geometric\n",
    "# !pip install ogb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nwwq0nSdmsOL"
   },
   "source": [
    "# 1 PyTorch Geometric (Datasets and Data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sf7vUmdNKCjA"
   },
   "source": [
    "PyTorch Geometric generally has two classes for storing or transforming the graphs into tensor format. One is the `torch_geometric.datasets`, which contains a variety of common graph datasets. Another one is `torch_geometric.data` that provides the data handling of graphs in PyTorch tensors.\n",
    "\n",
    "In this section, we will learn how to use the `torch_geometric.datasets` and `torch_geometric.data`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ic-o1P3r6hr2"
   },
   "source": [
    "## PyG Datasets\n",
    "\n",
    "The `torch_geometric.datasets` has many common graph datasets. Here we will explore the usage by using one example dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "zT5qca3x6XpG"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.chrsmrrs.com/graphkerneldatasets/ENZYMES.zip\n",
      "Extracting enzymes/ENZYMES/ENZYMES.zip\n",
      "Processing...\n",
      "Done!\n",
      "ENZYMES(600)\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.datasets import TUDataset\n",
    "\n",
    "root = './enzymes'\n",
    "name = 'ENZYMES'\n",
    "\n",
    "# The ENZYMES dataset\n",
    "pyg_dataset= TUDataset('./enzymes', 'ENZYMES')\n",
    "\n",
    "# You can find that there are 600 graphs in this dataset\n",
    "print(pyg_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__notebook_source__.ipynb  enzymes\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NLm5vVYMAP2x"
   },
   "source": [
    "## Question 1: What is the number of classes and number of features in the ENZYMES dataset? (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "8iF_Kyqr_JbY"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENZYMES dataset has 6 classes\n",
      "ENZYMES dataset has 3 features\n"
     ]
    }
   ],
   "source": [
    "def get_num_classes(pyg_dataset):\n",
    "    \n",
    "    # TODO: Implement this function that takes a PyG dataset object\n",
    "    # and return the number of classes for that dataset.\n",
    "\n",
    "    num_classes = 0\n",
    "\n",
    "    ############# Your code here ############\n",
    "    ## (~1 line of code)\n",
    "    ## Note\n",
    "    ## 1. Colab autocomplete functionality might be useful.\n",
    "    num_classes = pyg_dataset.num_classes\n",
    "    \n",
    "\n",
    "\n",
    "    #########################################\n",
    "\n",
    "    return num_classes\n",
    "\n",
    "def get_num_features(pyg_dataset):\n",
    "  # TODO: Implement this function that takes a PyG dataset object\n",
    "  # and return the number of features for that dataset.\n",
    "\n",
    "    num_features = 0\n",
    "\n",
    "    ############# Your code here ############\n",
    "    ## (~1 line of code)\n",
    "    ## Note\n",
    "    ## 1. Colab autocomplete functionality might be useful.\n",
    "    num_features = pyg_dataset.num_features\n",
    "\n",
    "    #########################################\n",
    "\n",
    "    return num_features\n",
    "\n",
    "# You may find that some information need to be stored in the dataset level,\n",
    "# specifically if there are multiple graphs in the dataset\n",
    "\n",
    "num_classes = get_num_classes(pyg_dataset)\n",
    "num_features = get_num_features(pyg_dataset)\n",
    "print(\"{} dataset has {} classes\".format(name, num_classes))\n",
    "print(\"{} dataset has {} features\".format(name, num_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The ENZYMES dataset has 600 graphs. The above functions allows us to look at the ENZYMES overall properties"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rwKbzhHUAckZ"
   },
   "source": [
    "## PyG Data\n",
    "\n",
    "Each PyG dataset usually stores a list of `torch_geometric.data.Data` objects. Each `torch_geometric.data.Data` object usually represents a graph. You can easily get the `Data` object by indexing on the dataset.\n",
    "\n",
    "For more information such as what will be stored in `Data` object, please refer to the [documentation](https://pytorch-geometric.readthedocs.io/en/latest/modules/data.html#torch_geometric.data.Data)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7sCV3xJWCddX"
   },
   "source": [
    "## Question 2: What is the label of the graph (index 100 in the ENZYMES dataset)? (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "LIis9oTZAfs3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(edge_index=[2, 168], x=[37, 3], y=[1])\n",
      "Graph with index 100 has label tensor([4])\n"
     ]
    }
   ],
   "source": [
    "def get_graph_class(pyg_dataset, idx):\n",
    "    # TODO: Implement this function that takes a PyG dataset object,\n",
    "    # the index of the graph in dataset, and returns the class/label \n",
    "    # of the graph (in integer).\n",
    "    \n",
    "    # here the idx refers to different graphs in the pyg_dataset\n",
    "\n",
    "    label = -1\n",
    "\n",
    "    ############# Your code here ############\n",
    "    ## (~1 line of code)\n",
    "    label = pyg_dataset[idx].y\n",
    "\n",
    "\n",
    "    #########################################\n",
    "\n",
    "    return label\n",
    "\n",
    "# Here pyg_dataset is a dataset for graph classification\n",
    "graph_0 = pyg_dataset[0]\n",
    "print(graph_0)\n",
    "idx = 100\n",
    "label = get_graph_class(pyg_dataset, idx)\n",
    "print('Graph with index {} has label {}'.format(idx, label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fKhcVeAhCwoY"
   },
   "source": [
    "## Question 3: What is the number of edges for the graph (index 200 in the ENZYMES dataset)? (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "f5m2DOfhBtWv"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph with index 200 has 53 edges\n"
     ]
    }
   ],
   "source": [
    "def get_graph_num_edges(pyg_dataset, idx):\n",
    "    # TODO: Implement this function that takes a PyG dataset object,\n",
    "    # the index of the graph in dataset, and returns the number of \n",
    "    # edges in the graph (in integer). You should not count an edge \n",
    "    # twice if the graph is undirected. For example, in an undirected \n",
    "    # graph G, if two nodes v and u are connected by an edge, this edge\n",
    "    # should only be counted once.\n",
    "    \n",
    "    # idx refers to a particular graph\n",
    "\n",
    "\n",
    "    num_edges = 0\n",
    "\n",
    "    ############# Your code here ############\n",
    "    ## Note:\n",
    "    ## 1. You can't return the data.num_edges directly\n",
    "    ## 2. We assume the graph is undirected\n",
    "    ## (~4 lines of code)\n",
    "    \n",
    "    \n",
    "    # lets iterate through the edge_index, (2,# of edge pairs from u to v)\n",
    "    num_edge_pairs = pyg_dataset[idx].edge_index.shape[1]\n",
    "    edge_pair_tensor = pyg_dataset[idx].edge_index\n",
    "    \n",
    "    # lets keep track of edges \n",
    "    edge_list = []\n",
    "    \n",
    "    for i in range(num_edge_pairs):\n",
    "        u = edge_pair_tensor[0,i]\n",
    "        v = edge_pair_tensor[1,i]\n",
    "        # check if the pair exist in edge_list,\n",
    "        # also considering undirected, if so, we skip\n",
    "        if ((u,v) in edge_list) or ((v,u) in edge_list):\n",
    "            continue\n",
    "        else:\n",
    "            edge_list.append((u,v))\n",
    "        \n",
    "    \n",
    "\n",
    "    #########################################\n",
    "    \n",
    "    num_edges = len(edge_list)\n",
    "    return num_edges\n",
    "\n",
    "idx = 200\n",
    "num_edges = get_graph_num_edges(pyg_dataset, idx)\n",
    "print('Graph with index {} has {} edges'.format(idx, num_edges))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AXa7yIG4E0Fp"
   },
   "source": [
    "# 2 Open Graph Benchmark (OGB)\n",
    "\n",
    "The Open Graph Benchmark (OGB) is a collection of realistic, large-scale, and diverse benchmark datasets for machine learning on graphs. Its datasets are automatically downloaded, processed, and split using the OGB Data Loader. The model performance can also be evaluated by using the OGB Evaluator in a unified manner."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HnazPGGAJAZN"
   },
   "source": [
    "## Dataset and Data\n",
    "\n",
    "OGB also supports the PyG dataset and data. Here we take a look on the `ogbn-arxiv` dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "Gpc6bTm3GF02"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://snap.stanford.edu/ogb/data/nodeproppred/arxiv.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloaded 0.08 GB: 100%|██████████| 81/81 [01:09<00:00,  1.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting dataset/arxiv.zip\n",
      "Processing...\n",
      "Loading necessary files...\n",
      "This might take a while.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 9058.97it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 5607.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing graphs...\n",
      "Converting graphs into PyG objects...\n",
      "Saving...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n",
      "The ogbn-arxiv dataset has 1 graph\n",
      "Data(adj_t=[169343, 169343, nnz=1166243], node_year=[169343, 1], x=[169343, 128], y=[169343, 1])\n"
     ]
    }
   ],
   "source": [
    "import torch_geometric.transforms as T\n",
    "from ogb.nodeproppred import PygNodePropPredDataset\n",
    "\n",
    "dataset_name = 'ogbn-arxiv'\n",
    "# Load the dataset and transform it to sparse tensor\n",
    "dataset = PygNodePropPredDataset(name=dataset_name,\n",
    "                                 transform=T.ToSparseTensor())\n",
    "print('The {} dataset has {} graph'.format(dataset_name, len(dataset)))\n",
    "\n",
    "# Extract the graph\n",
    "data = dataset[0] # we have 1 dataset anyway\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cw0xZJKZI-n3"
   },
   "source": [
    "## Question 4: What is the number of features in the ogbn-arxiv graph? (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "ZP844_nT2ZJl"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The graph has 128 features\n"
     ]
    }
   ],
   "source": [
    "def graph_num_features(data):\n",
    "    # TODO: Implement this function that takes a PyG data object,\n",
    "    # and returns the number of features in the graph (in integer).\n",
    "\n",
    "    num_features = 0\n",
    "\n",
    "    ############# Your code here ############\n",
    "    ## (~1 line of code)\n",
    "    num_features = data.num_features # (or alternative, we can just take .x.shape[1])\n",
    "\n",
    "    #########################################\n",
    "\n",
    "    return num_features\n",
    "\n",
    "num_features = graph_num_features(data)\n",
    "print('The graph has {} features'.format(num_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9DP_yEQZ0NVW"
   },
   "source": [
    "# 3 GNN: Node Property Prediction\n",
    "\n",
    "In this section we will build our first graph neural network by using PyTorch Geometric and apply it on node property prediction (node classification).\n",
    "\n",
    "We will build the graph neural network by using GCN operator ([Kipf et al. (2017)](https://arxiv.org/pdf/1609.02907.pdf)).\n",
    "\n",
    "You should use the PyG built-in `GCNConv` layer directly. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O4CcOUEoInjD"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "-DCtgcHpGIpd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "print(torch.__version__)\n",
    "\n",
    "# The PyG built-in GCNConv\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "import torch_geometric.transforms as T\n",
    "from ogb.nodeproppred import PygNodePropPredDataset, Evaluator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0IK9z0wQIwzQ"
   },
   "source": [
    "## Load and Preprocess the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "0ibJ0ieoIwQM"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "dataset_name = 'ogbn-arxiv'\n",
    "dataset = PygNodePropPredDataset(name=dataset_name,\n",
    "                                 transform=T.ToSparseTensor())\n",
    "data = dataset[0]\n",
    "\n",
    "# Make the adjacency matrix to symmetric\n",
    "# https://pytorch-geometric.readthedocs.io/en/latest/_modules/torch_geometric/transforms/to_undirected.html\n",
    "data.adj_t = data.adj_t.to_symmetric() # this makes it undirected \n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# If you use GPU, the device should be cuda\n",
    "print('Device: {}'.format(device))\n",
    "\n",
    "data = data.to(device)\n",
    "\"\"\"\n",
    "{'train': tensor([     0,      1,      2,  ..., 169145, 169148, 169251]),\n",
    " 'valid': tensor([   349,    357,    366,  ..., 169185, 169261, 169296]),\n",
    " 'test': tensor([   346,    398,    451,  ..., 169340, 169341, 169342])}\n",
    "\"\"\"\n",
    "split_idx = dataset.get_idx_split() # dict that contains train node index, valid node index and test node index \n",
    "train_idx = split_idx['train'].to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OgUA815bNJ8w"
   },
   "source": [
    "## GCN Model\n",
    "\n",
    "Now we will implement our GCN model!\n",
    "\n",
    "Please follow the figure below to implement your `forward` function.\n",
    "\n",
    "\n",
    "![test](https://drive.google.com/uc?id=128AuYAXNXGg7PIhJJ7e420DoPWKb-RtL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "IgspXTYpNJLA"
   },
   "outputs": [],
   "source": [
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, num_layers,\n",
    "                 dropout, return_embeds=False):\n",
    "        # TODO: Implement this function that initializes self.convs, \n",
    "        # self.bns, and self.softmax.\n",
    "\n",
    "        super(GCN, self).__init__()\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        # A list of GCNConv layers\n",
    "        # https://discuss.pytorch.org/t/when-should-i-use-nn-modulelist-and-when-should-i-use-nn-sequential/5463/4\n",
    "        self.convs = torch.nn.ModuleList([GCNConv(in_channels=input_dim,out_channels=hidden_dim)])\n",
    "        # extend if needed with list comprehension\n",
    "        # append if needed\n",
    "        self.convs.extend([GCNConv(in_channels=hidden_dim,out_channels=hidden_dim) for _ in range(1,num_layers-1)])\n",
    "        self.convs.append(GCNConv(in_channels=hidden_dim, out_channels=output_dim)) # last GCN\n",
    "\n",
    "        # A list of 1D batch normalization layers\n",
    "        self.bns = torch.nn.ModuleList([torch.nn.BatchNorm1d(num_features=hidden_dim) for _ in range(1,num_layers)])\n",
    "\n",
    "        # The log softmax layer\n",
    "        \n",
    "        # because later down in the assignment, nll_loss is use, so we need to convert the output to log-probabilities\n",
    "        # https://stackoverflow.com/questions/49036993/pytorch-softmax-what-dimension-to-use\n",
    "        # each row's output_dim logic should sum to 1\n",
    "        self.softmax = torch.nn.LogSoftmax(dim=1)\n",
    "\n",
    "        ############# Your code here ############\n",
    "        ## Note:\n",
    "        ## 1. You should use torch.nn.ModuleList for self.convs and self.bns\n",
    "        ## 2. self.convs has num_layers GCNConv layers\n",
    "        ## 3. self.bns has num_layers - 1 BatchNorm1d layers\n",
    "        ## 4. You should use torch.nn.LogSoftmax for self.softmax\n",
    "        ## 5. The parameters you can set for GCNConv include 'in_channels' and \n",
    "        ## 'out_channels'. More information please refer to the documentation:\n",
    "        ## https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#torch_geometric.nn.conv.GCNConv\n",
    "        ## 6. The only parameter you need to set for BatchNorm1d is 'num_features'\n",
    "        ## More information please refer to the documentation: \n",
    "        ## https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm1d.html\n",
    "        ## (~10 lines of code)\n",
    "\n",
    "        #########################################\n",
    "\n",
    "        # Probability of an element to be zeroed\n",
    "        self.dropout = dropout\n",
    "\n",
    "        # Skip classification layer and return node embeddings\n",
    "        self.return_embeds = return_embeds\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        for conv in self.convs:\n",
    "            conv.reset_parameters()\n",
    "        for bn in self.bns:\n",
    "            bn.reset_parameters()\n",
    "\n",
    "    def forward(self, x, adj_t):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        x: feature tensor\n",
    "        adj_t: SparseTensor that is like edge_index, pointing u to v\n",
    "        \"\"\"\n",
    "        # TODO: Implement this function that takes the feature tensor x,\n",
    "        # edge_index tensor adj_t and returns the output tensor as\n",
    "        # shown in the figure.\n",
    "\n",
    "        out = None\n",
    "\n",
    "        ############# Your code here ############\n",
    "        ## Note:\n",
    "        ## 1. Construct the network as showing in the figure\n",
    "        ## 2. torch.nn.functional.relu and torch.nn.functional.dropout are useful\n",
    "        ## More information please refer to the documentation:\n",
    "        ## https://pytorch.org/docs/stable/nn.functional.html\n",
    "        ## 3. Don't forget to set F.dropout training to self.training\n",
    "        ## 4. If return_embeds is True, then skip the last softmax layer\n",
    "        ## (~7 lines of code)\n",
    "        \n",
    "        for i in range(self.num_layers):\n",
    "            if i == 0:\n",
    "                # first layer\n",
    "                h = self.convs[i](x,adj_t)\n",
    "                h = self.bns[i](h)\n",
    "                h = torch.nn.ReLU()(h)\n",
    "                h = torch.nn.Dropout(self.dropout)(h)\n",
    "            elif i == self.num_layers-1:\n",
    "                # last layer\n",
    "                h = self.convs[i](h,adj_t)\n",
    "                out = self.softmax(h) # converts logit to log prob for n_ll later\n",
    "            else:\n",
    "                h = self.convs[i](h,adj_t)\n",
    "                h = self.bns[i](h)\n",
    "                h = torch.nn.ReLU()(h)\n",
    "                h = torch.nn.Dropout(self.dropout)(h)\n",
    "\n",
    "        #########################################\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN(\n",
      "  (convs): ModuleList(\n",
      "    (0): GCNConv(12, 5)\n",
      "    (1): GCNConv(5, 5)\n",
      "    (2): GCNConv(5, 4)\n",
      "  )\n",
      "  (bns): ModuleList(\n",
      "    (0): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (1): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (softmax): LogSoftmax(dim=1)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# test architecture\n",
    "temp_model = GCN(12,5,4,3,0.2)\n",
    "print(temp_model)\n",
    "del temp_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "FF1hnHUhO81e"
   },
   "outputs": [],
   "source": [
    "def train(model, data, train_idx, optimizer, loss_fn):\n",
    "    \"\"\"\n",
    "    Parameter\n",
    "    ---------\n",
    "    model: model class\n",
    "    data: torch_geometric.data.data.Data\n",
    "    train_idx: index of train nodes\n",
    "    optimzer:\n",
    "    loss_fn: loss criterion\n",
    "    \"\"\"\n",
    "    # TODO: Implement this function that trains the model by \n",
    "    # using the given optimizer and loss_fn.\n",
    "    \n",
    "    \n",
    "    # toggles layers dropout,bn for training\n",
    "    # https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch\n",
    "    model.train()\n",
    "    loss = 0\n",
    "\n",
    "    ############# Your code here ############\n",
    "    ## Note:\n",
    "    ## 1. Zero grad the optimizer\n",
    "    ## 2. Feed the data into the model\n",
    "    ## 3. Slicing the model output and label by train_idx\n",
    "    ## 4. Feed the sliced output and label to loss_fn\n",
    "    ## (~4 lines of code)\n",
    "\n",
    "    #########################################\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    y_pred = model(data.x, data.adj_t) # model expects x and edge_index(adj_t)\n",
    "    y_train = y_pred[train_idx]\n",
    "    # https://pytorch.org/docs/stable/generated/torch.nn.NLLLoss.html\n",
    "    loss = loss_fn(y_train,data.y[train_idx].squeeze())\n",
    "    \n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "aJdlrJQhPBsK"
   },
   "outputs": [],
   "source": [
    "# Test function here\n",
    "@torch.no_grad()\n",
    "def test(model, data, split_idx, evaluator):\n",
    "    # TODO: Implement this function that tests the model by \n",
    "    # using the given split_idx and evaluator.\n",
    "    model.eval()\n",
    "\n",
    "    # The output of model on all data\n",
    "    out = None\n",
    "\n",
    "    ############# Your code here ############\n",
    "    ## (~1 line of code)\n",
    "    ## Note:\n",
    "    ## 1. No index slicing here\n",
    "    out = model(data.x,data.adj_t)\n",
    "\n",
    "    #########################################\n",
    "\n",
    "    y_pred = out.argmax(dim=-1, keepdim=True)\n",
    "\n",
    "    train_acc = evaluator.eval({\n",
    "        'y_true': data.y[split_idx['train']],\n",
    "        'y_pred': y_pred[split_idx['train']],\n",
    "    })['acc']\n",
    "    valid_acc = evaluator.eval({\n",
    "        'y_true': data.y[split_idx['valid']],\n",
    "        'y_pred': y_pred[split_idx['valid']],\n",
    "    })['acc']\n",
    "    test_acc = evaluator.eval({\n",
    "        'y_true': data.y[split_idx['test']],\n",
    "        'y_pred': y_pred[split_idx['test']],\n",
    "    })['acc']\n",
    "\n",
    "    return train_acc, valid_acc, test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "o7F46xkuLiOL"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'device': 'cuda',\n",
       " 'num_layers': 3,\n",
       " 'hidden_dim': 256,\n",
       " 'dropout': 0.5,\n",
       " 'lr': 0.01,\n",
       " 'epochs': 100}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Please do not change the args\n",
    "args = {\n",
    "    'device': device,\n",
    "    'num_layers': 3,\n",
    "    'hidden_dim': 256,\n",
    "    'dropout': 0.5,\n",
    "    'lr': 0.01,\n",
    "    'epochs': 100,\n",
    "}\n",
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "dT8RyM2cPGxM"
   },
   "outputs": [],
   "source": [
    "model = GCN(data.num_features, args['hidden_dim'],\n",
    "            dataset.num_classes, args['num_layers'],\n",
    "            args['dropout']).to(device)\n",
    "evaluator = Evaluator(name='ogbn-arxiv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "id": "qd5O5cnPPdVF",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01, Loss: 3.9560, Train: 30.71%, Valid: 35.04% Test: 35.74%\n",
      "Epoch: 02, Loss: 2.4273, Train: 22.25%, Valid: 18.40% Test: 16.33%\n",
      "Epoch: 03, Loss: 1.9620, Train: 21.10%, Valid: 10.51% Test: 8.55%\n",
      "Epoch: 04, Loss: 1.8410, Train: 27.78%, Valid: 18.52% Test: 18.27%\n",
      "Epoch: 05, Loss: 1.6924, Train: 33.47%, Valid: 20.69% Test: 18.52%\n",
      "Epoch: 06, Loss: 1.6241, Train: 36.55%, Valid: 22.51% Test: 18.94%\n",
      "Epoch: 07, Loss: 1.5561, Train: 38.61%, Valid: 26.67% Test: 25.02%\n",
      "Epoch: 08, Loss: 1.4846, Train: 41.39%, Valid: 34.23% Test: 35.38%\n",
      "Epoch: 09, Loss: 1.4258, Train: 42.75%, Valid: 36.67% Test: 39.35%\n",
      "Epoch: 10, Loss: 1.3901, Train: 43.86%, Valid: 38.67% Test: 41.64%\n",
      "Epoch: 11, Loss: 1.3559, Train: 44.04%, Valid: 38.09% Test: 40.92%\n",
      "Epoch: 12, Loss: 1.3321, Train: 44.27%, Valid: 36.43% Test: 37.55%\n",
      "Epoch: 13, Loss: 1.3082, Train: 45.98%, Valid: 39.82% Test: 41.57%\n",
      "Epoch: 14, Loss: 1.2914, Train: 48.73%, Valid: 43.87% Test: 45.93%\n",
      "Epoch: 15, Loss: 1.2662, Train: 51.78%, Valid: 48.45% Test: 50.74%\n",
      "Epoch: 16, Loss: 1.2492, Train: 53.76%, Valid: 51.71% Test: 53.78%\n",
      "Epoch: 17, Loss: 1.2382, Train: 55.62%, Valid: 55.01% Test: 55.75%\n",
      "Epoch: 18, Loss: 1.2211, Train: 57.16%, Valid: 56.33% Test: 55.90%\n",
      "Epoch: 19, Loss: 1.2089, Train: 57.62%, Valid: 56.52% Test: 55.60%\n",
      "Epoch: 20, Loss: 1.1913, Train: 58.83%, Valid: 57.84% Test: 56.87%\n",
      "Epoch: 21, Loss: 1.1811, Train: 59.01%, Valid: 58.30% Test: 57.71%\n",
      "Epoch: 22, Loss: 1.1764, Train: 58.54%, Valid: 57.56% Test: 57.57%\n",
      "Epoch: 23, Loss: 1.1631, Train: 58.72%, Valid: 57.83% Test: 57.88%\n",
      "Epoch: 24, Loss: 1.1493, Train: 58.63%, Valid: 57.45% Test: 58.05%\n",
      "Epoch: 25, Loss: 1.1428, Train: 59.01%, Valid: 57.55% Test: 58.33%\n",
      "Epoch: 26, Loss: 1.1329, Train: 60.13%, Valid: 58.82% Test: 59.85%\n",
      "Epoch: 27, Loss: 1.1305, Train: 60.94%, Valid: 59.90% Test: 61.36%\n",
      "Epoch: 28, Loss: 1.1233, Train: 61.77%, Valid: 61.30% Test: 63.13%\n",
      "Epoch: 29, Loss: 1.1135, Train: 61.80%, Valid: 61.46% Test: 63.87%\n",
      "Epoch: 30, Loss: 1.1102, Train: 62.42%, Valid: 61.83% Test: 63.75%\n",
      "Epoch: 31, Loss: 1.1032, Train: 63.55%, Valid: 62.74% Test: 64.00%\n",
      "Epoch: 32, Loss: 1.0966, Train: 64.22%, Valid: 63.56% Test: 65.07%\n",
      "Epoch: 33, Loss: 1.0878, Train: 65.18%, Valid: 64.97% Test: 65.75%\n",
      "Epoch: 34, Loss: 1.0833, Train: 65.60%, Valid: 65.70% Test: 66.20%\n",
      "Epoch: 35, Loss: 1.0769, Train: 66.22%, Valid: 66.64% Test: 66.50%\n",
      "Epoch: 36, Loss: 1.0737, Train: 66.57%, Valid: 66.62% Test: 66.79%\n",
      "Epoch: 37, Loss: 1.0670, Train: 66.87%, Valid: 66.90% Test: 66.69%\n",
      "Epoch: 38, Loss: 1.0637, Train: 67.28%, Valid: 66.85% Test: 66.47%\n",
      "Epoch: 39, Loss: 1.0595, Train: 67.34%, Valid: 67.23% Test: 66.73%\n",
      "Epoch: 40, Loss: 1.0552, Train: 67.51%, Valid: 67.30% Test: 66.79%\n",
      "Epoch: 41, Loss: 1.0495, Train: 67.47%, Valid: 67.50% Test: 66.67%\n",
      "Epoch: 42, Loss: 1.0468, Train: 67.93%, Valid: 67.83% Test: 66.31%\n",
      "Epoch: 43, Loss: 1.0401, Train: 68.32%, Valid: 67.90% Test: 66.37%\n",
      "Epoch: 44, Loss: 1.0349, Train: 68.58%, Valid: 68.11% Test: 66.86%\n",
      "Epoch: 45, Loss: 1.0314, Train: 68.78%, Valid: 68.43% Test: 67.40%\n",
      "Epoch: 46, Loss: 1.0323, Train: 68.83%, Valid: 68.27% Test: 66.85%\n",
      "Epoch: 47, Loss: 1.0267, Train: 68.87%, Valid: 68.11% Test: 66.52%\n",
      "Epoch: 48, Loss: 1.0249, Train: 69.04%, Valid: 68.15% Test: 66.68%\n",
      "Epoch: 49, Loss: 1.0229, Train: 69.04%, Valid: 68.37% Test: 67.33%\n",
      "Epoch: 50, Loss: 1.0167, Train: 69.16%, Valid: 68.65% Test: 67.79%\n",
      "Epoch: 51, Loss: 1.0162, Train: 69.29%, Valid: 68.83% Test: 67.54%\n",
      "Epoch: 52, Loss: 1.0114, Train: 69.55%, Valid: 68.59% Test: 67.37%\n",
      "Epoch: 53, Loss: 1.0062, Train: 69.54%, Valid: 68.53% Test: 66.99%\n",
      "Epoch: 54, Loss: 1.0090, Train: 69.64%, Valid: 68.70% Test: 67.36%\n",
      "Epoch: 55, Loss: 1.0052, Train: 69.52%, Valid: 69.02% Test: 67.81%\n",
      "Epoch: 56, Loss: 0.9981, Train: 69.38%, Valid: 68.94% Test: 68.48%\n",
      "Epoch: 57, Loss: 0.9989, Train: 69.67%, Valid: 69.42% Test: 68.59%\n",
      "Epoch: 58, Loss: 0.9962, Train: 69.93%, Valid: 69.62% Test: 68.65%\n",
      "Epoch: 59, Loss: 0.9903, Train: 70.15%, Valid: 69.60% Test: 68.80%\n",
      "Epoch: 60, Loss: 0.9879, Train: 70.10%, Valid: 69.59% Test: 68.58%\n",
      "Epoch: 61, Loss: 0.9894, Train: 70.27%, Valid: 69.71% Test: 68.72%\n",
      "Epoch: 62, Loss: 0.9828, Train: 70.29%, Valid: 69.53% Test: 68.43%\n",
      "Epoch: 63, Loss: 0.9838, Train: 70.28%, Valid: 69.77% Test: 69.19%\n",
      "Epoch: 64, Loss: 0.9799, Train: 70.11%, Valid: 69.62% Test: 69.03%\n",
      "Epoch: 65, Loss: 0.9783, Train: 70.33%, Valid: 69.36% Test: 68.23%\n",
      "Epoch: 66, Loss: 0.9782, Train: 70.50%, Valid: 69.52% Test: 68.21%\n",
      "Epoch: 67, Loss: 0.9769, Train: 70.47%, Valid: 69.49% Test: 68.03%\n",
      "Epoch: 68, Loss: 0.9724, Train: 70.51%, Valid: 69.64% Test: 68.42%\n",
      "Epoch: 69, Loss: 0.9722, Train: 70.60%, Valid: 69.54% Test: 68.49%\n",
      "Epoch: 70, Loss: 0.9687, Train: 70.70%, Valid: 69.81% Test: 68.40%\n",
      "Epoch: 71, Loss: 0.9653, Train: 70.69%, Valid: 69.49% Test: 68.15%\n",
      "Epoch: 72, Loss: 0.9648, Train: 70.67%, Valid: 69.74% Test: 68.55%\n",
      "Epoch: 73, Loss: 0.9622, Train: 70.68%, Valid: 70.03% Test: 68.95%\n",
      "Epoch: 74, Loss: 0.9646, Train: 70.67%, Valid: 70.05% Test: 69.49%\n",
      "Epoch: 75, Loss: 0.9597, Train: 70.61%, Valid: 69.76% Test: 69.05%\n",
      "Epoch: 76, Loss: 0.9577, Train: 70.68%, Valid: 69.92% Test: 68.62%\n",
      "Epoch: 77, Loss: 0.9557, Train: 71.06%, Valid: 70.16% Test: 68.90%\n",
      "Epoch: 78, Loss: 0.9524, Train: 71.14%, Valid: 70.13% Test: 69.03%\n",
      "Epoch: 79, Loss: 0.9513, Train: 71.19%, Valid: 70.32% Test: 69.72%\n",
      "Epoch: 80, Loss: 0.9477, Train: 71.05%, Valid: 70.41% Test: 69.70%\n",
      "Epoch: 81, Loss: 0.9478, Train: 71.06%, Valid: 70.23% Test: 69.53%\n",
      "Epoch: 82, Loss: 0.9455, Train: 71.03%, Valid: 69.94% Test: 69.12%\n",
      "Epoch: 83, Loss: 0.9468, Train: 70.92%, Valid: 69.73% Test: 68.33%\n",
      "Epoch: 84, Loss: 0.9438, Train: 71.20%, Valid: 69.71% Test: 68.70%\n",
      "Epoch: 85, Loss: 0.9415, Train: 71.29%, Valid: 70.20% Test: 69.45%\n",
      "Epoch: 86, Loss: 0.9386, Train: 71.25%, Valid: 70.41% Test: 69.83%\n",
      "Epoch: 87, Loss: 0.9398, Train: 71.37%, Valid: 70.30% Test: 69.95%\n",
      "Epoch: 88, Loss: 0.9364, Train: 71.40%, Valid: 70.21% Test: 69.85%\n",
      "Epoch: 89, Loss: 0.9326, Train: 71.53%, Valid: 69.85% Test: 68.82%\n",
      "Epoch: 90, Loss: 0.9313, Train: 71.31%, Valid: 69.46% Test: 67.48%\n",
      "Epoch: 91, Loss: 0.9307, Train: 71.31%, Valid: 69.71% Test: 68.30%\n",
      "Epoch: 92, Loss: 0.9300, Train: 71.48%, Valid: 70.46% Test: 69.66%\n",
      "Epoch: 93, Loss: 0.9280, Train: 71.47%, Valid: 70.34% Test: 69.70%\n",
      "Epoch: 94, Loss: 0.9258, Train: 71.70%, Valid: 70.27% Test: 69.04%\n",
      "Epoch: 95, Loss: 0.9288, Train: 71.65%, Valid: 70.29% Test: 69.05%\n",
      "Epoch: 96, Loss: 0.9225, Train: 71.63%, Valid: 70.08% Test: 68.91%\n",
      "Epoch: 97, Loss: 0.9220, Train: 71.40%, Valid: 69.87% Test: 68.85%\n",
      "Epoch: 98, Loss: 0.9215, Train: 71.56%, Valid: 70.12% Test: 68.93%\n",
      "Epoch: 99, Loss: 0.9199, Train: 71.70%, Valid: 70.28% Test: 68.47%\n",
      "Epoch: 100, Loss: 0.9165, Train: 71.73%, Valid: 70.37% Test: 69.77%\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "# reset the parameters to initial random value\n",
    "model.reset_parameters()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=args['lr'])\n",
    "loss_fn = F.nll_loss\n",
    "\n",
    "best_model = None\n",
    "best_valid_acc = 0\n",
    "\n",
    "for epoch in range(1, 1 + args[\"epochs\"]):    \n",
    "    loss = train(model, data, train_idx, optimizer, loss_fn)\n",
    "    result = test(model, data, split_idx, evaluator)\n",
    "    train_acc, valid_acc, test_acc = result\n",
    "    if valid_acc > best_valid_acc:\n",
    "        best_valid_acc = valid_acc\n",
    "        best_model = copy.deepcopy(model)\n",
    "    print(f'Epoch: {epoch:02d}, '\n",
    "        f'Loss: {loss:.4f}, '\n",
    "        f'Train: {100 * train_acc:.2f}%, '\n",
    "        f'Valid: {100 * valid_acc:.2f}% '\n",
    "        f'Test: {100 * test_acc:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "id": "EqcextqOL2FX"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: Train: 71.52%, Valid: 70.24% Test: 69.64%\n"
     ]
    }
   ],
   "source": [
    "best_result = test(best_model, data, split_idx, evaluator)\n",
    "train_acc, valid_acc, test_acc = best_result\n",
    "print(f'Best model: '\n",
    "      f'Train: {100 * train_acc:.2f}%, '\n",
    "      f'Valid: {100 * valid_acc:.2f}% '\n",
    "      f'Test: {100 * test_acc:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "duMEg-olLjbJ"
   },
   "source": [
    "## Question 5: What are your `best_model` validation and test accuracy? Please report them on Gradescope. For example, for an accuracy such as 50.01%, just report 50.01 and please don't include the percent sign. (20 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R8pOD6y80TyI"
   },
   "source": [
    "# 4 GNN: Graph Property Prediction\n",
    "\n",
    "In this section we will create a graph neural network for graph property prediction (graph classification)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vRg5VOEdQTa4"
   },
   "source": [
    "## Load and preprocess the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "id": "LXb-O5QUIgTH"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://snap.stanford.edu/ogb/data/graphproppred/csv_mol_download/hiv.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloaded 0.00 GB: 100%|██████████| 3/3 [00:01<00:00,  2.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting dataset/hiv.zip\n",
      "Processing...\n",
      "Loading necessary files...\n",
      "This might take a while.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 6866/41127 [00:00<00:00, 68648.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing graphs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41127/41127 [00:00<00:00, 67963.38it/s]\n",
      " 28%|██▊       | 11391/41127 [00:00<00:00, 113906.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting graphs into PyG objects...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41127/41127 [00:00<00:00, 66629.23it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving...\n",
      "Done!\n",
      "Device: cuda\n",
      "Task type: binary classification\n"
     ]
    }
   ],
   "source": [
    "from ogb.graphproppred import PygGraphPropPredDataset, Evaluator\n",
    "from torch_geometric.data import DataLoader\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Load the dataset \n",
    "dataset = PygGraphPropPredDataset(name='ogbg-molhiv')\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('Device: {}'.format(device))\n",
    "\n",
    "split_idx = dataset.get_idx_split()\n",
    "\n",
    "# Check task type\n",
    "print('Task type: {}'.format(dataset.task_type))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "id": "7cHHbgW1c5hi"
   },
   "outputs": [],
   "source": [
    "# Load the data sets into dataloader\n",
    "# We will train the graph classification task on a batch of 32 graphs\n",
    "# Shuffle the order of graphs for training set\n",
    "train_loader = DataLoader(dataset[split_idx[\"train\"]], batch_size=32, shuffle=True, num_workers=0)\n",
    "valid_loader = DataLoader(dataset[split_idx[\"valid\"]], batch_size=32, shuffle=False, num_workers=0)\n",
    "test_loader = DataLoader(dataset[split_idx[\"test\"]], batch_size=32, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "id": "AYrSnOj0Y4DK"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'device': 'cuda',\n",
       " 'num_layers': 5,\n",
       " 'hidden_dim': 256,\n",
       " 'dropout': 0.5,\n",
       " 'lr': 0.001,\n",
       " 'epochs': 30}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Please do not change the args\n",
    "args = {\n",
    "    'device': device,\n",
    "    'num_layers': 5,\n",
    "    'hidden_dim': 256,\n",
    "    'dropout': 0.5,\n",
    "    'lr': 0.001,\n",
    "    'epochs': 30,\n",
    "}\n",
    "args"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extra: for further understand of the dataset and graph prediction problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is the number of output dim. 1 here means we are doing a logloss k = 2 problem \n",
    "# (since later we will use binary cross entropy)\n",
    "dataset.num_tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41127"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# there are 41127 unique graphs. Each sample is a graph with its own x and y \n",
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([19, 9])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# each graph sample has varying nodes and 9 features\n",
    "dataset[0].x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([18, 9])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[50].x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# since we are doing a graph binary classification, each graph sample has 1 label\n",
    "dataset[0].y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0 ---\n",
      "torch.Size([831, 9])\n",
      "torch.Size([32, 1])\n",
      "Batch 1 ---\n",
      "torch.Size([778, 9])\n",
      "torch.Size([32, 1])\n",
      "Batch 2 ---\n",
      "torch.Size([835, 9])\n",
      "torch.Size([32, 1])\n"
     ]
    }
   ],
   "source": [
    "# we can see train_loader automatically concats the graphs into a 2 dimensional tensor on its node index dimension (dim =0)\n",
    "for i, batch in enumerate(train_loader):\n",
    "    print(f\"Batch {i} ---\")\n",
    "    print(batch.x.shape)\n",
    "    print(batch.y.shape)\n",
    "    \n",
    "    if i == 2:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can see the above that each batch consist of 32 labels (because there are 32 graphs)\n",
    "# but the features are all concat. So how does our model knows to output 32 labels given x concat tensor? \n",
    "# Which x features belong to which graph???!\n",
    "# Ans- the global pooling graph layer\n",
    "# which requires the batch tensor (this tensor contains index of the 32 graph for the batch.x data)\n",
    "\n",
    "# the model's global mean graph pooling layer will pool the features to (32,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  2,  2,  2,  2,  2,  2,\n",
       "         2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
       "         2,  2,  2,  2,  2,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,\n",
       "         3,  3,  3,  3,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,\n",
       "         4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  5,  5,  5,  5,  5,  5,  5,\n",
       "         5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,\n",
       "         5,  5,  5,  5,  5,  5,  5,  5,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,\n",
       "         6,  6,  6,  6,  6,  6,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,\n",
       "         7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  8,  8,  8,  8,  8,  8,\n",
       "         8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  9,  9,  9,  9,  9,\n",
       "         9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,\n",
       "         9, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "        10, 10, 10, 10, 10, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11,\n",
       "        11, 11, 11, 11, 11, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12,\n",
       "        12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 13, 13, 13, 13,\n",
       "        13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13,\n",
       "        13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13,\n",
       "        13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13,\n",
       "        13, 13, 13, 13, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14,\n",
       "        14, 14, 14, 14, 14, 14, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n",
       "        15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n",
       "        15, 15, 15, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "        16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "        16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 17, 17, 17, 17, 17, 17, 17,\n",
       "        17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 18, 18, 18, 18,\n",
       "        18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 19, 19, 19, 19, 19, 19,\n",
       "        19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19,\n",
       "        19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19,\n",
       "        19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19,\n",
       "        20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "        20, 20, 20, 20, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21,\n",
       "        21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 22, 22, 22, 22, 22,\n",
       "        22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22,\n",
       "        22, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 24,\n",
       "        24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 25, 25,\n",
       "        25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 26, 26, 26,\n",
       "        26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26,\n",
       "        26, 26, 26, 26, 26, 26, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27,\n",
       "        27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 28, 28, 28, 28, 28, 28,\n",
       "        28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 29, 29, 29, 29,\n",
       "        29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29,\n",
       "        29, 29, 29, 29, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30,\n",
       "        30, 30, 30, 30, 30, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31,\n",
       "        31, 31, 31, 31, 31, 31, 31], device='cuda:0')"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# here is the dataloader's batch's batch index which indicates which row of batch.x belongs to graph i where i = 0,1/...batch_size\n",
    "batch.batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7WLhguSTeazy"
   },
   "source": [
    "## Graph Prediction Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u05Z14TRYPGn"
   },
   "source": [
    "Now we will implement our GCN Graph Prediction model!\n",
    "\n",
    "We will reuse the existing GCN model to generate `node_embeddings` and use  Global Pooling on the nodes to predict properties for the whole graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "id": "3_Kq3zyjeZ22"
   },
   "outputs": [],
   "source": [
    "from ogb.graphproppred.mol_encoder import AtomEncoder\n",
    "from torch_geometric.nn import global_add_pool, global_mean_pool\n",
    "\n",
    "### GCN to predict graph property\n",
    "class GCN_Graph(torch.nn.Module):\n",
    "    def __init__(self, hidden_dim, output_dim, num_layers, dropout):\n",
    "        super(GCN_Graph, self).__init__()\n",
    "\n",
    "        # Load encoders for Atoms in molecule graphs\n",
    "        # encodes x to (x,hidden_dim)\n",
    "        self.node_encoder = AtomEncoder(hidden_dim)\n",
    "\n",
    "        # Node embedding model\n",
    "        # Note that the input_dim and output_dim are set to hidden_dim\n",
    "        self.gnn_node = GCN(hidden_dim, hidden_dim,\n",
    "            hidden_dim, num_layers, dropout, return_embeds=True)\n",
    "\n",
    "#         self.pool = None\n",
    "\n",
    "        ############# Your code here ############\n",
    "        ## Note:\n",
    "        ## 1. Initialize the self.pool to global mean pooling layer\n",
    "        ## More information please refer to the documentation:\n",
    "        ## https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#global-pooling-layers\n",
    "        ## (~1 line of code)\n",
    "        \n",
    "        self.pool = global_mean_pool\n",
    "\n",
    "        #########################################\n",
    "\n",
    "        # Output layer\n",
    "        self.linear = torch.nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.gnn_node.reset_parameters()\n",
    "        self.linear.reset_parameters()\n",
    "\n",
    "    def forward(self, batched_data):\n",
    "        # TODO: Implement this function that takes the input tensor batched_data,\n",
    "        # returns a batched output tensor for each graph.\n",
    "        # unwraps batched_data\n",
    "        x, edge_index, batch = batched_data.x, batched_data.edge_index, batched_data.batch\n",
    "        embed = self.node_encoder(x)\n",
    "        ############# Your code here ############\n",
    "        ## Note:\n",
    "        ## 1. Construct node embeddings using existing GCN model\n",
    "        ## 2. Use global pooling layer to construct features for the whole graph\n",
    "        ## More information please refer to the documentation:\n",
    "        ## https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#global-pooling-layers\n",
    "        ## 3. Use a linear layer to predict the graph property \n",
    "        ## (~3 lines of code)\n",
    "        out = self.gnn_node(embed,edge_index)\n",
    "        out = self.pool(out,batch) # this layer pools the \n",
    "        out = self.linear(out)\n",
    "        \n",
    "\n",
    "        #########################################\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "id": "FJjnGuMSbjX0"
   },
   "outputs": [],
   "source": [
    "def train(model, device, data_loader, optimizer, loss_fn):\n",
    "    \n",
    "    # TODO: Implement this function that trains the model by \n",
    "    # using the given optimizer and loss_fn.\n",
    "    model.train()\n",
    "#     loss = 0\n",
    "\n",
    "    for step, batch in enumerate(tqdm(data_loader, desc=\"Iteration\")):\n",
    "        batch = batch.to(device)\n",
    "        if batch.x.shape[0] == 1 or batch.batch[-1] == 0:\n",
    "            pass\n",
    "        else:\n",
    "            \n",
    "            ## ignore nan targets (unlabeled) when computing training loss.\n",
    "            is_labeled = batch.y == batch.y\n",
    "\n",
    "            ############# Your code here ############\n",
    "            ## Note:\n",
    "            ## 1. Zero grad the optimizer\n",
    "            ## 2. Feed the data into the model\n",
    "            ## 3. Use `is_labeled` mask to filter output and labels\n",
    "            ## 4. You might change the type of label\n",
    "            ## 5. Feed the output and label to loss_fn\n",
    "            ## (~3 lines of code)\n",
    "            optimizer.zero_grad()\n",
    "            y_pred = model(batch)\n",
    "            y_train = y_pred[is_labeled]\n",
    "            \n",
    "            # cast to float\n",
    "            loss = loss_fn(y_train,batch.y[is_labeled].squeeze().to(torch.float))\n",
    "\n",
    "            #########################################\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "id": "ztPHXq_Gzn7U"
   },
   "outputs": [],
   "source": [
    "# The evaluation function\n",
    "def eval(model, device, loader, evaluator):\n",
    "    model.eval()\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "\n",
    "    for step, batch in enumerate(tqdm(loader, desc=\"Iteration\")):\n",
    "        batch = batch.to(device)\n",
    "\n",
    "        if batch.x.shape[0] == 1:\n",
    "            pass\n",
    "        else:\n",
    "            with torch.no_grad():\n",
    "                pred = model(batch)\n",
    "\n",
    "            y_true.append(batch.y.view(pred.shape).detach().cpu())\n",
    "            y_pred.append(pred.detach().cpu()) # send back to cpu because batch is in device gpu\n",
    "\n",
    "    y_true = torch.cat(y_true, dim = 0).numpy()\n",
    "    y_pred = torch.cat(y_pred, dim = 0).numpy()\n",
    "\n",
    "    input_dict = {\"y_true\": y_true, \"y_pred\": y_pred}\n",
    "\n",
    "    return evaluator.eval(input_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "id": "MR1wQ4hMZeMw"
   },
   "outputs": [],
   "source": [
    "model = GCN_Graph(args['hidden_dim'],\n",
    "            dataset.num_tasks, args['num_layers'],\n",
    "            args['dropout']).to(device)\n",
    "evaluator = Evaluator(name='ogbg-molhiv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "id": "qJGTNZiuZy0A",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b513bab754704f7e839f79a3efade073",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/1029 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d854feda0934dbaa1927d2423c3900c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/1029 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b558109775c43ab98582e8238a7eba1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/129 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8484da40fa3c4640b392abe1f6e1bfc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/129 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01, Loss: 0.0290, Train: 70.02%, Valid: 73.57% Test: 72.67%\n",
      "Training...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "736e1f04fc3b4630977d8be9eb417e21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/1029 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c07c2b0b589472cabac7cbc02705cff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/1029 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "962cc5f36a6644e8baebc4638566356e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/129 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48679b71c95047b896d3aa5f6976f5db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/129 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f586562418a4077a0d54e78e633d77c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/1029 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a9c0c57baea44fd9fe97473e1efaa51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/1029 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3aa39dc4903441a79998d59cdfa09bac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/129 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "925d4ab7c10647749538934ba6ffa23e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/129 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2efdf168782141c69605f735064820f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/1029 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee54678389544a28b69e9595560b3357",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/1029 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "635b9b05ab8743508c56cd142231946f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/129 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "018f0c2d98f84026bb68d04df7bd5b16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/129 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "896911f0bdd24981ab4eaacd96b32cf3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/1029 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d621503f3c6493aa7bae0a0b1762241",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/1029 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ed182a877604eadb26f313d1280fbba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/129 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "902f61f52cd54518a41432850a6c0f8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/129 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "caf0012163fc4321b5abbb5f8a6b128b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/1029 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb02e3016f314495a3aafc64779e0d34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/1029 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c401e925c60146549e40920311a91897",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/129 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d67a13cd869f4ec6ab9bb2b7685d0f0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/129 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 06, Loss: 0.0187, Train: 76.96%, Valid: 77.96% Test: 73.85%\n",
      "Training...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1c048e08d0d4d32bf350579134c7845",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/1029 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "525da691710b494598a6bf1863a8a361",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/1029 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16dabf5abc0447438eafb83377719ac7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/129 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92983985b5344e2195fae91a4160b310",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/129 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c182d2ee77f4488b87eebc8d342ddd83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/1029 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9e9298a1d174106aaefe02430eaa338",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/1029 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c255b540fe14a5e9cadc6084536ec37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/129 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "451d97db6f2541ea97b160e64b4f29ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/129 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4c70a428f5e494b9336469a49db123d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/1029 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd9e5dc646684ff59ed026ad466aaecf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/1029 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6623caa7ae0843e99bae1fc34d0cebc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/129 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da9c04f5748c45418ef7cf2fff685b77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/129 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99d3d31953be4a7181e5f94ea905a8c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/1029 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93dd4d961841404f846cd82f396518aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/1029 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40aa53b34f7e4a4ab120588c0184e35f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/129 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0078d8b8160468fb57f7c42e059d1cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/129 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3e12dbe7dab4a6b9eb1230880fd10b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/1029 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93cb27b99f794f0394d69ce96f32bb37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/1029 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fec4a81fe724598a2bcad1fdfd533f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/129 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c55f3c257be04c66975650b183f32952",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/129 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a98938b73ed742458d41ea46e29fe1a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/1029 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c81ef67c7cd34a918e95488b3a2f6a31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/1029 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d88312855ae2429385d9d38cf1cf7574",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/129 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23eab8f7ab51429ca176427f00bbb199",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/129 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12, Loss: 0.0381, Train: 79.12%, Valid: 78.45% Test: 73.02%\n",
      "Training...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ae0c6e6eca9432c96de1950615b1340",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/1029 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b10ac2ed9fa649df81046de7d83497cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/1029 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b28fa21327844d6db2e89cbb72a32584",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/129 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "363927c72366408cbcb71a54a8cdae50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/129 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bace8ebb37c548fcb9b2d9622c482d3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/1029 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1386a324747e4f63834c93a30bd505cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/1029 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdb33ae22cb04bb694431ad836a53bb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/129 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b0c9e1f0699475a9f5bf9307aa99589",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/129 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7062abb6a5644614b6c226fdd81b70aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/1029 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b724b04e6529407e9df4200b4127c1b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/1029 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30a2beb42de44e06b0c75e48fad2025d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/129 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9fd88583f6f4bc79abc4946d6437b04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/129 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01ce7eea42a04a1897418c23ef143371",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/1029 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1803cbb2087e43a18ce1472f37463f2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/1029 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43edc07665fb45328f68f362e07f4235",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/129 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50ee17f4bcb342a29a7569f0ef6ba124",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/129 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11e370ea6c924e1c8262ba36398bbcea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/1029 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eeea563943524d58b264f760f8afaf2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/1029 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59cda16d53a24967b624af8eb89ad43e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/129 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44b2d71b23af472da329f8af249b2f1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/129 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7181420f5cee4b718902c97f5ec1edea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/1029 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4231e8d5e19748e5a010632a5780ec0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/1029 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68b32a5651b643d0981f53cfdaa739f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/129 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ee21d102fb24cb0ba0b486f00d606f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/129 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c48a75e0486142c8957af0d32276bf2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/1029 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "623c7d03ba2d48da8b62bae5e7fc9ff6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/1029 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c08eacf91ba6449c93047bf0dfc787ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/129 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7876cab2d47b43afacc3d3fff348c252",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/129 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 19, Loss: 0.5390, Train: 80.30%, Valid: 78.62% Test: 73.57%\n",
      "Training...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e132aa72a36e4ddea6d9480f6d1add05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/1029 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28d1db3d99504bd380c52dfe5ecea643",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/1029 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94af960e4c4a4e48ae0dcd82fd15a656",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/129 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e48bc64b87db4b66b91be6940faa2a85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/129 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "111f77e91d754a36adb50b591a701d97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/1029 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81819462be6746efb0b46a300c01d67a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/1029 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "883f4d048a624be194495ddb769fb75e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/129 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8aaf4552644c467a85222a3db3698fd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/129 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec4eeec36f5b4fcb9cd67152b5d42111",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/1029 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00ade17c1a124598a4fa58652f644f1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/1029 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "388f0ff0b9464b50bc771ace4b978822",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/129 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7020fcaa063b4315a4bcb2e304852882",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/129 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ed91e6108ae47d39de8b7385b117524",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/1029 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21cafca898da4e30be0fbc972e266e8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/1029 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3771a4d5627a4258a325c770cb56c938",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/129 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4eab5ed6fcc47a08020957f040ffc93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/129 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 23, Loss: 0.1708, Train: 81.94%, Valid: 80.54% Test: 73.44%\n",
      "Training...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4a83c9e03d6455a9342bdbc8194056f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/1029 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb4877e5c7b24d23866eac0c8175b329",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/1029 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "243169970e144c018ae90adc5d297e83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/129 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92a5df49954e4649b1754b40210228ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/129 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d95f7ecd0a74f9486af8753c2e34b10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/1029 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ca64f2b514647818a697a35ee0dae6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/1029 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4174124fb3f143888e13d4dbce847b1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/129 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c0009f49c2d46db966bcc9eb8b14a11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/129 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31ec58c043694d0bb617f4e998ed1962",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/1029 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5b79994d5c147cc9e39a3f6159ab85b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/1029 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61ca14198f0341c0bceeef79c4d32f17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/129 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63869d94fb474ae0a2e74c232030ba3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/129 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bbd10e645524ea19d36b7d1dc2026f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/1029 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a418e3c924464883a8f34d4aee70651c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/1029 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe21ef3775aa4578853f65c2f6e8a4b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/129 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cd8c092f68641b58c6489efacafe832",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/129 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c36af4e85df1415a883fbcabac7fed30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/1029 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8505ce887e2c4bb2942dc3846ce2eef2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/1029 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1abda9eb5c634894924b4762788efc8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/129 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78a79fab492840999fc193dbf6d718fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/129 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42999bd38e4f4668be2c9648477fa524",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/1029 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6370a26005bd4b71930c67d8b784a7ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/1029 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe1d9b345a7e49e18712578514da9b1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/129 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "051cb5d2116e466b8b937748a64b81bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/129 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a26128bfa4194c92bfc024224cc966f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/1029 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "071a6b9859d34419bc0493cbc2a408ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/1029 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1b360b97a434904b564cfd95bd0d7d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/129 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e06f5722a4744adb02b56c6f8671e3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/129 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "model.reset_parameters()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=args['lr'])\n",
    "loss_fn = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "best_model = None\n",
    "best_valid_acc = 0\n",
    "\n",
    "for epoch in range(1, 1 + args[\"epochs\"]):\n",
    "    print('Training...')\n",
    "    loss = train(model, device, train_loader, optimizer, loss_fn)\n",
    "\n",
    "    print('Evaluating...')\n",
    "    # evaluator probably just evaluates different metrics and returns them in a dict\n",
    "    train_result = eval(model, device, train_loader, evaluator)\n",
    "    val_result = eval(model, device, valid_loader, evaluator)\n",
    "    test_result = eval(model, device, test_loader, evaluator)\n",
    "    \n",
    "    # dataset.eval_metric = 'rocauc'\n",
    "    # extract key rocauc\n",
    "    train_acc, valid_acc, test_acc = train_result[dataset.eval_metric], val_result[dataset.eval_metric], test_result[dataset.eval_metric]\n",
    "    if valid_acc > best_valid_acc:\n",
    "        best_valid_acc = valid_acc\n",
    "        best_model = copy.deepcopy(model)\n",
    "        print(f'Epoch: {epoch:02d}, '\n",
    "        f'Loss: {loss:.4f}, '\n",
    "        f'Train: {100 * train_acc:.2f}%, '\n",
    "        f'Valid: {100 * valid_acc:.2f}% '\n",
    "        f'Test: {100 * test_acc:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "id": "Oq5QaG21dOOO"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56d2cf9e2ff446e08fb4ae03c657c7d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/1029 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c66ca6e12d14515b9f137bb1d585e66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/129 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5a5d29f5cbc4a65914b5a05ecf29aed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/129 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: Train: 81.03%, Valid: 77.66% Test: 72.81%\n"
     ]
    }
   ],
   "source": [
    "train_acc = eval(best_model, device, train_loader, evaluator)[dataset.eval_metric]\n",
    "valid_acc = eval(best_model, device, valid_loader, evaluator)[dataset.eval_metric]\n",
    "test_acc = eval(best_model, device, test_loader, evaluator)[dataset.eval_metric]\n",
    "\n",
    "print(f'Best model: '\n",
    "      f'Train: {100 * train_acc:.2f}%, '\n",
    "      f'Valid: {100 * valid_acc:.2f}% '\n",
    "      f'Test: {100 * test_acc:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-uKs6j6t1ah3"
   },
   "source": [
    "## Question 6: What are your `best_model` validation and test ROC-AUC score? Please report them on Gradescope. For example, for an ROC-AUC score such as 50.01%, just report 50.01 and please don't include the percent sign. (20 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gBi_t8n0iZ4P"
   },
   "source": [
    "## Question 7 (Optional): Experiment with other two global pooling layers other than mean pooling in Pytorch Geometric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "taxEEWyh1_jq"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e7JXsMTBgeOI"
   },
   "source": [
    "# Submission\n",
    "\n",
    "In order to get credit, you must go submit your answers on Gradescope.\n",
    "\n",
    "Also, you need to submit the `ipynb` file of Colab 2, by clicking `File` and `Download .ipynb`. Please make sure that your output of each cell is available in your `ipynb` file."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
